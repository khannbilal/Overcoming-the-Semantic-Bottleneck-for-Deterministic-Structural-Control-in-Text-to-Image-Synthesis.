{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Infrastructure_and_Models\n**Purpose:** Deterministic environment setup, global configuration, and base model provenance.\n\n**Scope:**\n* Sets up the PyTorch environment and global seeds.\n* Defines the central configuration (paths, precision, hyperparameters).\n* Loads and freezes the base Stable Diffusion backbone (UNet, VAE, Text Encoder).\n* Performs integrity checks on loaded weights.\n\n**Exclusions:**\n* No image generation or sampling.\n* No training or optimization loops.\n* No visualization.","metadata":{}},{"cell_type":"markdown","source":"## Reproducibility Contract\n* **Deterministic Seeds:** `42` is used as the global seed for Python, NumPy, and PyTorch.\n* **Hardware Config:** Precision is locked to `float16` (or `bfloat16` if available) on CUDA.\n* **Artifacts:** All models loaded here form the immutable basis for subsequent experiments.\n* **Persistence:** Configuration and model metadata are saved to `outputs/init_snapshot.json`.","metadata":{}},{"cell_type":"code","source":"import sys\nimport torch\nimport diffusers\nimport transformers\nimport numpy as np\n\nprint(f\"Python Version: {sys.version.split()[0]}\")\nprint(f\"PyTorch Version: {torch.__version__}\")\nprint(f\"Diffusers Version: {diffusers.__version__}\")\nprint(f\"Transformers Version: {transformers.__version__}\")\nprint(f\"CUDA Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport json\nimport warnings\nimport logging\nfrom pathlib import Path\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom diffusers import StableDiffusionPipeline, DDIMScheduler\nfrom transformers import CLIPTextModel, CLIPTokenizer, CLIPImageProcessor\n\nwarnings.filterwarnings(\"ignore\")\nlogging.getLogger(\"diffusers\").setLevel(logging.ERROR)\nlogging.getLogger(\"transformers\").setLevel(logging.ERROR)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def seed_everything(seed=42):\n    \"\"\"\n    Enforces deterministic seeding across all libraries.\n    \"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    print(f\"Global seed set to: {seed}\")\n\nGLOBAL_SEED = 42\nseed_everything(GLOBAL_SEED)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Config:\n    \"\"\"\n    Central configuration for the entire research pipeline.\n    \"\"\"\n    PROJECT_NAME = \"Latent_Prompt_Injection\"\n    Seed = GLOBAL_SEED\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    PRECISION = torch.float16 \n    MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n    SCHEDULER_ID = \"runwayml/stable-diffusion-v1-5\"\n    OUTPUT_ROOT = Path(\"experiments\")\n    \n    LATENT_DIM = 4\n    LATENT_RES = 64\n    MAX_SEQ_LEN = 77\n\nconfig = Config()\nprint(f\"Configuration loaded. Device: {config.DEVICE}, Precision: {config.PRECISION}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def setup_directories(root_dir):\n    \"\"\"\n    Creates the standard directory tree for experiment artifacts.\n    \"\"\"\n    dirs = {\n        \"outputs\": root_dir / \"outputs\",\n        \"checkpoints\": root_dir / \"checkpoints\",\n        \"logs\": root_dir / \"logs\",\n        \"figures\": root_dir / \"figures\",\n        \"metadata\": root_dir / \"metadata\"\n    }\n    \n    for key, path in dirs.items():\n        path.mkdir(parents=True, exist_ok=True)\n        print(f\"Confirmed directory: {path}\")\n        \n    return dirs\n\ndirs = setup_directories(config.OUTPUT_ROOT)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_base_models(cfg):\n    \"\"\"\n    Loads and freezes the base Stable Diffusion components.\n    Returns individual components for granular control in N2.\n    \"\"\"\n    print(f\"Loading models from {cfg.MODEL_ID}...\")\n    scheduler = DDIMScheduler.from_pretrained(cfg.MODEL_ID, subfolder=\"scheduler\")\n    \n    vae = StableDiffusionPipeline.from_pretrained(\n        cfg.MODEL_ID, \n        subfolder=\"vae\",\n        torch_dtype=cfg.PRECISION\n    ).vae.to(cfg.DEVICE)\n    \n    unet = StableDiffusionPipeline.from_pretrained(\n        cfg.MODEL_ID, \n        subfolder=\"unet\",\n        torch_dtype=cfg.PRECISION\n    ).unet.to(cfg.DEVICE)\n\n    text_encoder = CLIPTextModel.from_pretrained(\n        cfg.MODEL_ID, \n        subfolder=\"text_encoder\", \n        torch_dtype=cfg.PRECISION\n    ).to(cfg.DEVICE)\n    tokenizer = CLIPTokenizer.from_pretrained(cfg.MODEL_ID, subfolder=\"tokenizer\")\n    \n    vae.requires_grad_(False)\n    unet.requires_grad_(False)\n    text_encoder.requires_grad_(False)\n    return tokenizer, text_encoder, unet, vae, scheduler\n\ntokenizer, text_encoder, unet, vae, scheduler = load_base_models(config)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Performing Integrity checks\")\n\nassert text_encoder.device.type == config.DEVICE.type, \"Text Encoder on wrong device\"\nassert unet.device.type == config.DEVICE.type, \"UNet on wrong device\"\nassert vae.device.type == config.DEVICE.type, \"VAE on wrong device\"\nassert unet.dtype == config.PRECISION, f\"UNet dtype mismatch. Expected {config.PRECISION}, got {unet.dtype}\"\n\nunet_params = sum(p.numel() for p in unet.parameters())\nvae_params = sum(p.numel() for p in vae.parameters())\nprint(f\"Integrity Verified.\")\nprint(f\"UNet Parameters:{unet_params:,}\")\nprint(f\"VAE Parameters:{vae_params:,}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_registry = {\n    \"tokenizer\": tokenizer,\n    \"text_encoder\": text_encoder,\n    \"unet\": unet,\n    \"vae\": vae,\n    \"scheduler\": scheduler,\n    \"config\": config,\n    \"dirs\": dirs\n}\n\nprint(\"Model Registry initialized.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup Complete\n**Artifacts Produced:**\n1.  Locked Global Seed (`42`)\n2.  Frozen Model Registry (UNet, VAE, Text Encoder)\n3.  Experiment Directory Structure\n4.  `init_snapshot.json` for audit\n\n**Next Steps:**\nThese artifacts are now ready to be consumed by **Notebook 02: `02_latent_manipulation_and_generation.ipynb`** for the core latent prompt injection methodology.","metadata":{}}]}