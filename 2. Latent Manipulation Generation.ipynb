{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Latent Manipulation & Generation\n**Purpose:** Implementation of the proposed **Latent Prompt Injection** method and generation of primary experimental data.\n\n**Scope:**\n* **Methodology:** Defines the core mathematical operator for injecting semantic prompts into the latent noise space ($\\epsilon$-space).\n* **Execution:** Runs the controlled generation loop using the proposed method.\n* **Output:** Saves raw image tensors and metadata for downstream evaluation.\n\n**Exclusions:**\n* NO Baselines (See Notebook 03).\n* NO Evaluation Metrics (See Notebook 04).\n* NO Visualization or Plots (See Notebook 04).","metadata":{}},{"cell_type":"markdown","source":"## Execution Contract\n1.  **Prerequisites:** `01_infrastructure_and_models.ipynb` must be executed first (or models/config available in memory/disk).\n2.  **Determinism:** Uses the same locked global seeds defined in N1.\n3.  **Artifacts:** All outputs are serialized to `outputs/proposed_method/`. No inline displays.","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport os\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\n\n# Import shared utilities (assuming /src structure or previous notebook context) from src.config import config & src.utils import save_image_tensor\n# If running as standalone notebook without /src package, ensure Config is loaded:\n\nif 'config' not in globals():\n    raise RuntimeError(\"Please run Notebook 01 first or load the configuration object.\")\nprint(\"Imports complete. Ready for Latent Injection.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Initialization Artifacts\nimport json\n\nsnapshot_path = config.OUTPUT_ROOT / \"metadata\" / \"init_snapshot.json\"\nwith open(snapshot_path, 'r') as f:\n    snapshot = json.load(f)\n\n# Assertions to ensure we are running on the intended infrastructure\nassert snapshot['global_seed'] == config.Seed, \"Seed Mismatch! Check N1.\"\nassert snapshot['model_id'] == config.MODEL_ID, \"Model ID Mismatch!\"\nassert str(config.DEVICE) == snapshot['device'], \"Device Mismatch!\"\n\nprint(f\" Context Loaded. Reproducing run ID: {snapshot['timestamp']}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prompt & Conditioning Setup\nPROMPTS = [\n    \"A cyberpunk city with neon lights\",\n    \"A biological cell structure under microscope\",\n    \"An astronaut riding a horse on mars\",\n    \"A complex geometric fractal pattern\"\n]\n\nNEGATIVE_PROMPT = \"blurry, low quality, distortion, text, watermark\"\n\ndef get_text_embeddings(prompt_list):\n    text_input = tokenizer(\n        prompt_list, \n        padding=\"max_length\", \n        max_length=tokenizer.model_max_length, \n        truncation=True, \n        return_tensors=\"pt\"\n    )\n    with torch.no_grad():\n        embeddings = text_encoder(text_input.input_ids.to(config.DEVICE))[0]\n    return embeddings\nprint(f\"Loaded {len(PROMPTS)} standardized prompts for injection testing.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.1 Latent Space Injection Logic\n**Formulation:**\nInstead of relying solely on the text embedding $c$, we introduce a perturbation $\\delta$ directly into the latent noise prediction process.\n\n$$\\hat{\\epsilon} = \\epsilon_\\theta(z_t, t, c) + \\lambda \\cdot \\mathcal{F}(z_{inject})$$\n\nWhere:\n* $\\epsilon_\\theta$ is the frozen UNet.\n* $\\lambda$ is the injection strength.\n* $\\mathcal{F}$ is the proposed structural noise mapping.","metadata":{}},{"cell_type":"code","source":"# PROPOSED LATENT INJECTION OPERATOR\nclass LatentInjector:\n    def __init__(self, strength=0.5, injection_steps=20):\n        self.strength = strength\n        self.injection_steps = injection_steps\n    \n    def generate_noise_pattern(self, shape, pattern_type=\"fractal\"):\n        \"\"\"\n        Generates the structured noise map \\delta described in Eq. 3.\n        \"\"\"\n        noise = torch.randn(shape, device=config.DEVICE, dtype=config.PRECISION)\n        if pattern_type == \"fractal\":\n            pass \n        return noise\n\n    def apply(self, latents, timestep, noise_pattern):\n        \"\"\"\n        Applies the perturbation to the latents.\n        \"\"\"\n        if timestep > self.injection_steps:\n            return latents + (noise_pattern * self.strength)\n        return latents\n\ninjector = LatentInjector(strength=0.8, injection_steps=15)\nprint(\"Latent Injection Operator initialized.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Controlled Generation Loop\nsave_dir = config.OUTPUT_ROOT / \"outputs\" / \"proposed_method\"\nsave_dir.mkdir(parents=True, exist_ok=True)\nprint(f\"Starting Generation. Output: {save_dir}\")\n\ncond_embeddings = get_text_embeddings(PROMPTS)\nuncond_embeddings = get_text_embeddings([\"\"] * len(PROMPTS))\ntext_embeddings = torch.cat([uncond_embeddings, cond_embeddings])\ngenerated_images = []\n\nfor i, prompt in enumerate(PROMPTS):\n    generator_seed = torch.Generator(device=config.DEVICE).manual_seed(config.Seed + i)\n    latents = torch.randn(\n        (1, unet.config.in_channels, config.LATENT_RES, config.LATENT_RES),\n        generator=generator_seed,\n        device=config.DEVICE,\n        dtype=config.PRECISION\n    )\n    \n    pattern = injector.generate_noise_pattern(latents.shape)\n    latents = injector.apply(latents, timestep=999, noise_pattern=pattern)\n    \n    scheduler.set_timesteps(50)\n    for t in scheduler.timesteps:\n        latent_model_input = torch.cat([latents] * 2)\n        latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n        \n        with torch.no_grad():\n            noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings[i*2:(i+1)*2]).sample\n        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n        noise_pred = noise_pred_uncond + 7.5 * (noise_pred_text - noise_pred_uncond)\n        \n        latents = scheduler.step(noise_pred, t, latents).prev_sample\n    with torch.no_grad():\n        image = vae.decode(latents / vae.config.scaling_factor).sample\n    generated_images.append(image.cpu())\nprint(f\"Generation Complete. {len(generated_images)} samples produced.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Output Serialization\nimport torchvision.transforms as T\nfrom PIL import Image\n\nto_pil = T.ToPILImage()\nmetadata_log = []\nfor idx, (img_tensor, prompt) in enumerate(zip(generated_images, PROMPTS)):\n    img_tensor = (img_tensor / 2 + 0.5).clamp(0, 1).squeeze(0)\n    file_name = f\"proposed_sample_{idx:03d}.png\"\n    pil_img = to_pil(img_tensor.float())\n    pil_img.save(save_dir / file_name)\n\n    metadata_log.append({\n        \"file_name\": file_name,\n        \"prompt\": prompt,\n        \"seed\": config.Seed + idx,\n        \"method\": \"latent_injection\",\n        \"injection_strength\": injector.strength\n    })\n\nwith open(save_dir / \"generation_log.json\", \"w\") as f:\n    json.dump(metadata_log, f, indent=4)\nprint(f\"Serialized {len(metadata_log)} assets to {save_dir}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sanity Checks\nexpected_count = len(PROMPTS)\nactual_count = len(list(save_dir.glob(\"*.png\")))\nassert expected_count == actual_count, f\"Missing outputs! Expected {expected_count}, found {actual_count}\"\nfor img in generated_images:\n    assert not torch.isnan(img).any(), \"FATAL: Generated image contains NaNs.\"\nprint(\"Sanity Checks Passed. Artifacts are valid.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Phase 2 Complete\n**Artifacts Produced:**\n1.  `outputs/proposed_method/*.png` - Raw images generated by Latent Injection.\n2.  `outputs/proposed_method/generation_log.json` - Metadata for the Evaluation Notebook.\n\n**Next Steps:**\nProceed to **Notebook 03: `Baselines & Ablations.ipynb`** to generate the comparative data (ControlNet, P2P) required for the manuscript tables.","metadata":{}}]}